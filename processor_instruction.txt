import json
import logging
import os
import asyncio

from app_init.app_init import ai_service, entity_service
from common.config.config import ENTITY_VERSION, TRINO_AI_API
from common.service.trino_service import get_trino_schema_id_by_entity_name
from common.util.utils import read_json_file, parse_json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Use meta to get token.
# 'data' is the current entity data. You can find the entity data model in {current_entity_name}.json file, which is available in your session context.
# Study the data model before writing any code.
# In the process function, you can work with the current entity data, analyze it, get other entities to which the current entity has references, and add new "dependent" entities.

async def process_name(meta, data):
    """Example process function. This is where the core business logic goes."""
    try:
        # Retrieve the entity based on its ID from the entity service.
        entity = await entity_service.get_item(meta["token"], some_entity_name, ENTITY_VERSION, data["id"])

        # Process the entity and create a dependent entity.
        dependant_entity_data = data["dependent_entity_data"]

        # Add the dependent entity using the entity service.
        dependant_entity_id = await entity_service.add_item(
            meta["token"], dependant_entity_name, ENTITY_VERSION, dependant_entity_data
        )
        data["dependent_entity"] = {"technical_id": dependant_entity_id}
        #no need to update current entity - it will be done automatically, but dependant entities should be updated manually if necessary
        logger.info("Dependent entity added successfully.")
    except Exception as e:
        logger.error(f"Error in process_name: {e}")
        raise


async def data_aggregation_process_name(meta, data):
    """Example of an asynchronous function to aggregate data."""
    try:
        # Read the schema file that defines the structure for aggregated data.
        base_dir = os.path.abspath(os.path.join(__file__, "../../../"))
        aggregated_data_entity_path = os.path.join(base_dir, 'aggregated_data_entity', 'aggregated_data_entity.json')
        aggregated_data_entity_schema = await read_json_file(aggregated_data_entity_path)

        # Make API call to AI service to generate aggregated data report based on schema.
        aggregated_data = await ai_service.ai_chat(
            token=meta["token"],
            chat_id=await get_trino_schema_id_by_entity_name("response_data_entity"),
            ai_endpoint=TRINO_AI_API,
            ai_question=f"Could you please return json report based on this schema: {json.dumps(aggregated_data_entity_schema)}. Return only json"
        )

        # Parse and validate the returned JSON data.
        aggregated_data_entity_data = json.loads(parse_json(aggregated_data))

        # Store the aggregated data entity and get its ID.
        aggregated_data_entity_id = await entity_service.add_item(
            meta["token"], "aggregated_data_entity", ENTITY_VERSION, aggregated_data_entity_data
        )

        logger.info("Aggregated data entity added successfully.")
    except Exception as e:
        logger.error(f"Error in data_aggregation_process_name: {e}")
        raise

# Test example to show how to handle async function calls in unit tests:

class TestSendEmailProcess(unittest.TestCase):

    @patch("app_init.app_init.entity_service.add_item")
    @patch("app_init.app_init.ai_service.ai_chat")
    def test_send_email_process(self, mock_ai_chat, mock_entity_service):
        # Arrange: mock dependencies
        mock_ai_chat.return_value = '{"aggregated_data": "dummy_aggregated_data"}'
        mock_entity_service.return_value = "aggregated_data_entity_id"

        meta = {"token": "test_token"}
        data = {}

        # Act: Execute the async function using asyncio.run()
        asyncio.run(data_aggregation_process_name(meta, data))

        # Assert: Verify that the correct methods were called with the expected arguments
        mock_entity_service.assert_called_once_with(
            meta["token"], "aggregated_data_entity", ENTITY_VERSION, {"aggregated_data": "dummy_aggregated_data"}
        )

# Uncomment the line below to run the tests when this script is executed directly
if __name__ == '__main__':
    unittest.main()
